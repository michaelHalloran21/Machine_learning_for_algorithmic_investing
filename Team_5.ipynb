{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO/lhe0OxuP/EDIOmd9UWUb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/michaelHalloran21/Stock_Prediction_with_Machine_Learning/blob/main/Team_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "gbmZcfj8kwBj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3db5d2e1-06b6-4ee6-ad9b-04f4d89b7588"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.11/dist-packages (0.2.51)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.0)\n",
            "Requirement already satisfied: quantstats in /usr/local/lib/python3.11/dist-packages (0.0.64)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.32.3)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.11/dist-packages (from yfinance) (0.0.11)\n",
            "Requirement already satisfied: lxml>=4.9.1 in /usr/local/lib/python3.11/dist-packages (from yfinance) (5.3.0)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from yfinance) (4.3.6)\n",
            "Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2024.2)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.4.6)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.11/dist-packages (from yfinance) (3.17.8)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.11/dist-packages (from yfinance) (4.12.3)\n",
            "Requirement already satisfied: html5lib>=1.1 in /usr/local/lib/python3.11/dist-packages (from yfinance) (1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: tabulate>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from quantstats) (0.9.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.6)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.11/dist-packages (from html5lib>=1.1->yfinance) (1.17.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from html5lib>=1.1->yfinance) (0.5.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (2024.12.14)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "gfortran is already the newest version (4:11.2.0-1ubuntu1).\n",
            "libatlas-base-dev is already the newest version (3.10.3-12ubuntu1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "# Required libraries\n",
        "!pip install yfinance pandas numpy matplotlib seaborn scikit-learn quantstats tqdm\n",
        "!apt-get install -y libatlas-base-dev gfortran"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import quantstats as qs\n",
        "\n",
        "from datetime import datetime\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "GzND3T4Lbve_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a folder for data storage\n",
        "data_folder = \"stock_data\"\n",
        "os.makedirs(data_folder, exist_ok=True)"
      ],
      "metadata": {
        "id": "DFSbe64neqoX"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to download stock data\n",
        "def download_data(ticker, start, end):\n",
        "    \"\"\"Download stock data for a specific ticker.\"\"\"\n",
        "    try:\n",
        "        data = yf.download(ticker, start=start, end=end)\n",
        "        if 'Adj Close' not in data.columns:\n",
        "            data['Adj Close'] = data['Close']  # Fallback to Close if Adj Close is missing\n",
        "        data['Ticker'] = ticker  # Add ticker column for identification\n",
        "        data['Log Returns'] = np.log(data['Adj Close'] / data['Adj Close'].shift(1))\n",
        "        return data.dropna()\n",
        "    except Exception as e:\n",
        "        print(f\"Error downloading data for {ticker}: {e}\")\n",
        "        return pd.DataFrame()  # Return empty DataFrame on failure"
      ],
      "metadata": {
        "id": "dVDzybqxbycd"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download and combine data\n",
        "def download_and_combine_data(tickers, start, end):\n",
        "    \"\"\"Download stock data for all tickers and combine them into one DataFrame.\"\"\"\n",
        "    combined_data = []\n",
        "    for ticker in tqdm(tickers, desc=\"Downloading stock data\"):\n",
        "        data = download_data(ticker, start, end)\n",
        "        if not data.empty:\n",
        "            combined_data.append(data)\n",
        "    return pd.concat(combined_data) if combined_data else pd.DataFrame()"
      ],
      "metadata": {
        "id": "tZV_MWZ7ewWm"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fetch S&P 500 tickers\n",
        "url = \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\"\n",
        "sp500_tickers = pd.read_html(url)[0]['Symbol'].tolist()"
      ],
      "metadata": {
        "id": "VeadvHvQfLBK"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define date range\n",
        "start_date = \"2015-01-01\"\n",
        "end_date = datetime.now().strftime(\"%Y-%m-%d\")"
      ],
      "metadata": {
        "id": "ys5x4n3Rg0Sm"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download and save data\n",
        "print(\"Downloading stock data...\")\n",
        "stock_data = download_and_combine_data(sp500_tickers[:50], start_date, end_date)  # Limit to 50 for demo\n",
        "if not stock_data.empty:\n",
        "    stock_data.to_csv(\"stock_data/combined_stock_data.csv\", index=False)\n",
        "    print(\"Data saved to 'stock_data/combined_stock_data.csv'\")\n",
        "else:\n",
        "    print(\"No data downloaded. Exiting.\")\n",
        "    exit()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44yD5PiufCIc",
        "outputId": "497286d8-3a50-4010-906e-7a5979a2eb8a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading stock data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Downloading stock data: 100%|██████████| 50/50 [00:10<00:00,  4.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data saved to 'stock_data/combined_stock_data.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stock_data.columns = [\n",
        "    '_'.join([str(level) for level in col if level])\n",
        "    for col in stock_data.columns\n",
        "]"
      ],
      "metadata": {
        "id": "iWLRoxzmkw8y"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure no duplicate column names\n",
        "if stock_data.columns.duplicated().any():\n",
        "    print(\"Duplicate column names found. Renaming...\")\n",
        "    stock_data.columns = pd.io.parsers.ParserBase({'names': stock_data.columns})._maybe_dedup_names(stock_data.columns)\n"
      ],
      "metadata": {
        "id": "nb5t9X2plezS"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_features(stock_data):\n",
        "    # Compute new features\n",
        "    sma_10 = stock_data['Adj Close'].rolling(window=10).mean()\n",
        "    sma_50 = stock_data['Adj Close'].rolling(window=50).mean()\n",
        "    ema_12 = stock_data['Adj Close'].ewm(span=12, adjust=False).mean()\n",
        "    ema_26 = stock_data['Adj Close'].ewm(span=26, adjust=False).mean()\n",
        "    macd = ema_12 - ema_26\n",
        "\n",
        "    # Calculate RSI\n",
        "    delta = stock_data['Adj Close'].diff(1)\n",
        "    gain = delta.where(delta > 0, 0)\n",
        "    loss = -delta.where(delta < 0, 0)\n",
        "    avg_gain = gain.rolling(window=14).mean()\n",
        "    avg_loss = loss.rolling(window=14).mean()\n",
        "    rs = avg_gain / avg_loss\n",
        "    rsi = 100 - (100 / (1 + rs))\n",
        "\n",
        "    # Combine all features into a single DataFrame\n",
        "    features = pd.DataFrame({\n",
        "        'SMA_10': sma_10,\n",
        "        'SMA_50': sma_50,\n",
        "        'EMA_12': ema_12,\n",
        "        'EMA_26': ema_26,\n",
        "        'MACD': macd,\n",
        "        'RSI': rsi\n",
        "    }, index=stock_data.index)\n",
        "\n",
        "    # Concatenate the new features with the original DataFrame\n",
        "    stock_data = pd.concat([stock_data, features], axis=1)\n",
        "\n",
        "    return stock_data"
      ],
      "metadata": {
        "id": "5aopOBeFb1SM"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add features\n",
        "stock_data = add_features(stock_data)"
      ],
      "metadata": {
        "id": "WM6f4GpPcCi5"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add labels for machine learning\n",
        "def define_labels(data):\n",
        "    \"\"\"Create target labels for training.\"\"\"\n",
        "    data['Target'] = np.where(data['Log Returns'].shift(-1) > 0, 1, 0)\n",
        "    return data"
      ],
      "metadata": {
        "id": "phhuXwWBb5MT"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add labels\n",
        "stock_data = define_labels(stock_data)"
      ],
      "metadata": {
        "id": "UWljWP88cEb5"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare data for training\n",
        "features = ['SMA_10', 'SMA_50', 'RSI', 'MACD']\n",
        "# Drop rows with NaN in 'Log Returns'\n",
        "stock_data = stock_data.dropna(subset=['Log Returns'])\n",
        "# Drop NaN values across features and target to ensure alignment\n",
        "data = stock_data[features + ['Target']].dropna()"
      ],
      "metadata": {
        "id": "y7kyx2qpb6-e"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate features and target\n",
        "X = data[features]\n",
        "y = data['Target']"
      ],
      "metadata": {
        "id": "AHuLiqysnAkx"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check alignment\n",
        "assert len(X) == len(y), \"X and y are not aligned!\""
      ],
      "metadata": {
        "id": "n6-1T4ren6_h"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "stock_data = stock_data.loc[X.index]  # Align stock_data to training/testing indices"
      ],
      "metadata": {
        "id": "8R-gAQzjhFOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train a Random Forest model\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "F_hoCBfIcH1C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "y_pred = model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "izUkui8LcK9y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure predictions have a unique index\n",
        "predictions = pd.Series(y_pred, index=X_test.index, name=\"Predicted_Signal\")"
      ],
      "metadata": {
        "id": "tekEP1OU1vdk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure predictions have a unique index\n",
        "if not predictions.index.is_unique:\n",
        "    print(\"Duplicate indices found in predictions. Dropping duplicates...\")\n",
        "    predictions = predictions.loc[~predictions.index.duplicated(keep='first')]"
      ],
      "metadata": {
        "id": "Wz-BUxTlpJkg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Align predictions index with stock_data\n",
        "aligned_indices = predictions.index.intersection(stock_data.index)\n",
        "predictions = predictions.loc[aligned_indices]\n",
        "stock_data = stock_data.loc[aligned_indices]\n"
      ],
      "metadata": {
        "id": "esnm7ytl1vnl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Backtest\n",
        "def backtest(stock_data, predictions):\n",
        "    predictions.index = stock_data.loc[X_test.index].index  # Align predictions with stock_data\n",
        "\n",
        "    backtest_data = stock_data.loc[predictions.index].copy()  # Align indices\n",
        "\n",
        "    # Strategy returns based on predictions\n",
        "    backtest_data['Strategy'] = predictions.shift(1) * backtest_data['Log Returns']\n",
        "\n",
        "    # Cumulative returns\n",
        "    backtest_data['Cumulative Market Returns'] = (1 + backtest_data['Log Returns']).cumprod()\n",
        "    backtest_data['Cumulative Strategy Returns'] = (1 + backtest_data['Strategy']).cumprod()\n",
        "\n",
        "    # Plot cumulative returns\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(backtest_data.index, backtest_data['Cumulative Strategy Returns'], label='Strategy', color='blue')\n",
        "    plt.plot(backtest_data.index, backtest_data['Cumulative Market Returns'], label='Market', color='orange')\n",
        "    plt.title('Backtest: Strategy vs. Market')\n",
        "    plt.xlabel('Date')\n",
        "    plt.ylabel('Cumulative Returns')\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "G1UGUq0rb9WU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assert len(stock_data.loc[predictions.index]) == len(predictions), \"Length mismatch between stock_data and predictions!\""
      ],
      "metadata": {
        "id": "LrK-jINa3W48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the updated backtest\n",
        "backtested_data = backtest(stock_data, predictions)"
      ],
      "metadata": {
        "id": "0dIFzxRycBAT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use Quantstats for advanced analysis\n",
        "if 'Strategy_Returns' in stock_data.columns:\n",
        "    qs.reports.full(stock_data['Strategy_Returns'].dropna())\n",
        "else:\n",
        "    print(\"No Strategy_Returns found in stock_data for Quantstats analysis.\")"
      ],
      "metadata": {
        "id": "RPZLS-ePcUyR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WU4Jxms2cXXF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}